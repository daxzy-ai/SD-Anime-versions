{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# üìä Preparador de Lora de Hollowstrawberry\n",
        "\n",
        "Este colab viene de [esta gu√≠a](https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#index). Te permitir√° obtener tus im√°genes y tags para entrenar Loras.\n",
        "\n",
        "Basado en el trabajo de [Kohya_ss y Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb#scrollTo=-Z4w3lfFKLjr). ¬°Gracias!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BJTp5PVN_q-"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "cBa7KdewQ4BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e499722d-f653-42bc-c6a5-dc5b484d5dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ¬°Proyecto Sofia listo!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "  from google.colab.output import clear as clear_output\n",
        "else:\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "#@title ## üö© Empezar aqu√≠\n",
        "\n",
        "#@markdown ### 1Ô∏è‚É£  Inicio\n",
        "#@markdown Esta celda cargar√° algunos requerimientos y crear√° las carpetas correspondientes en tu Google Drive. <p>\n",
        "#@markdown Tu nombre de proyecto ser√° la carpeta donde trabajaremos. No se permiten espacios.\n",
        "nombre_proyecto = \"Sofia\" #@param {type:\"string\"}\n",
        "project_name = nombre_proyecto.strip()\n",
        "#@markdown La estructura de carpetas no importa y es por comodidad. Aseg√∫rate de siempre elegir la misma. Me gusta organizar por proyecto.\n",
        "estructura_de_carpetas = \"Organizar por categor√≠a (MyDrive/lora_training/datasets/nombre_proyecto)\" #@param [\"Organizar por categor√≠a (MyDrive/lora_training/datasets/nombre_proyecto)\", \"Organizar por proyecto (MyDrive/Loras/nombre_proyecto/dataset)\"]\n",
        "folder_structure = estructura_de_carpetas\n",
        "\n",
        "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n",
        "  print(\"Por favor elige un nombre v√°lido.\")\n",
        "else:\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"üìÇ Conectando a Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\"/\")]\n",
        "  project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n",
        "\n",
        "  root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "  deps_dir = os.path.join(root_dir, \"deps\")\n",
        "  \n",
        "  if \"/Loras\" in folder_structure:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, project_base)\n",
        "    images_folder = os.path.join(main_dir, project_base, \"dataset\")\n",
        "    if \"/\" in project_name:\n",
        "      images_folder = os.path.join(images_folder, project_subfolder)\n",
        "  else:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "\n",
        "  for dir in [main_dir, deps_dir, images_folder, config_folder]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  print(f\"‚úÖ ¬°Proyecto {project_name} listo!\")\n",
        "  step1_installed_flag = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "afu5dCKTV31E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3dbc8311-b803-45a1-9ccd-d1a4c23bd9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Se encontraron 123 resultados\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "[¬°Click aqu√≠ para verlos en tu navegador!](https://gelbooru.com/index.php?page=post&s=list&tags=mavis_dracula)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì© Obteniendo lista de im√°genes...\n",
            "üåê Enlaces guardados a /content/drive/MyDrive/lora_training/config/Sofia/scrape_Sofia.txt\n",
            "\n",
            "üîÅ Descargando im√°genes ...\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3f731c|\u001b[1;32mOK\u001b[0m  |   1.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6f5d1f4669d74e69669ba388e0acfc21.png\n",
            "cf3418|\u001b[1;32mOK\u001b[0m  |   4.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/e299c153947efb53a0680b3948805f7f.jpg\n",
            "629a7a|\u001b[1;32mOK\u001b[0m  |   7.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/9cb26846b3f150afa4d559f5fdb60e37.jpeg\n",
            "df4c47|\u001b[1;32mOK\u001b[0m  |   3.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/22961a2cb0156c3f16e777d6f318ed6d.png\n",
            "1317e2|\u001b[1;32mOK\u001b[0m  |   4.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/0146aea7de35f4eeb0249cc1f377fa7d.png\n",
            "fee438|\u001b[1;32mOK\u001b[0m  |   3.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/dc3101aca848e637873fabb233ed4bdf.jpeg\n",
            "7d5b1b|\u001b[1;32mOK\u001b[0m  |    34MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5e4e333aa6b9601610fb56154897fc46.png\n",
            "9ce3cc|\u001b[1;32mOK\u001b[0m  |   4.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/16ffa6be274ac435fd2fb5df4194d466.jpeg\n",
            "90a068|\u001b[1;32mOK\u001b[0m  |    42MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/07ed3dd5b38a6c0cad9cc00207dc04aa.png\n",
            "5efc38|\u001b[1;32mOK\u001b[0m  |    15MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/ccd4ad3699abcbdf5b69f52c07f75a7a.jpg\n",
            "6c9d7c|\u001b[1;32mOK\u001b[0m  |   5.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_a73291fee27c5c7bf00ee43d3080012b.jpg\n",
            "c96073|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/9db7baa5b6a92623bac5ca46a0482e3f.png\n",
            "8d3b3a|\u001b[1;32mOK\u001b[0m  |    11MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/cd07761bedc3fb5c72f24e410ed13294.jpg\n",
            "75c275|\u001b[1;32mOK\u001b[0m  |    24MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/7f3f139a196d27cb398e3b24c25b9b74.png\n",
            "592ed7|\u001b[1;32mOK\u001b[0m  |    31MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/13db803de712e68e02a433f29ebc5ed0.png\n",
            "f4ccf2|\u001b[1;32mOK\u001b[0m  |    38MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/709bb91b40adb4add36275098dfc6bc5.png\n",
            "9f8e90|\u001b[1;32mOK\u001b[0m  |   4.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/8ffa0838280a0f01adf18b973be8d3bf.jpeg\n",
            "d40b74|\u001b[1;32mOK\u001b[0m  |   4.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/db9403c331b4bbb38c0f44487f4edc14.png\n",
            "e3c4da|\u001b[1;32mOK\u001b[0m  |   3.7MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/1806de584dcc8ba814f20390658aba05.jpg\n",
            "b2ddb8|\u001b[1;32mOK\u001b[0m  |   5.3MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/b147289494e3124c233d22f6ebed361a.jpeg\n",
            "20d0db|\u001b[1;32mOK\u001b[0m  |    21MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/3dd232dd44fa4169042c316df0053dcf.png\n",
            "fc5a2b|\u001b[1;32mOK\u001b[0m  |   2.3MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/4f113dc5e2f216196bb18c061bf6c151.jpg\n",
            "fd5c6a|\u001b[1;32mOK\u001b[0m  |   4.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/e5bfba2bf03ca8aa877d531896c74cbf.jpg\n",
            "7a5fdd|\u001b[1;32mOK\u001b[0m  |   4.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/429cb0cf801e53fc50d7750b0791f87b.jpg\n",
            "76298b|\u001b[1;32mOK\u001b[0m  |    50MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/9ddec5257d3fc8c35df96d88b0743442.png\n",
            "8e0c00|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/08fbc6310d6394add85cc8849b2ec82d.jpeg\n",
            "9a542d|\u001b[1;32mOK\u001b[0m  |   2.6MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/a3ed9212009da2885080d31ab48632e7.jpeg\n",
            "a8375a|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/d4110bdfac3ef9904685291b19eae285.png\n",
            "6f3123|\u001b[1;32mOK\u001b[0m  |   9.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/61327191964edd670f0ad61029c1c588.png\n",
            "a1e090|\u001b[1;32mOK\u001b[0m  |   1.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/750f2574c22fc0a5b8d1183774a70787.png\n",
            "bfe78f|\u001b[1;32mOK\u001b[0m  |   2.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/74d5be53c4d8c5596f554c71c9265fc4.jpg\n",
            "3c3e0d|\u001b[1;32mOK\u001b[0m  |    16MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6cf0b1a69399f5d76631c4b1734f619e.png\n",
            "fcd938|\u001b[1;32mOK\u001b[0m  |    38MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/892d69f5267c8ff20f59ff5c09b530b0.png\n",
            "50e5f4|\u001b[1;32mOK\u001b[0m  |   4.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/7ca79023f1b4c3dc6e6861d329b95064.jpg\n",
            "03dcf5|\u001b[1;32mOK\u001b[0m  |   3.3MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/92f5c999bb7abd5ef3efa5d5fd79a8dc.jpeg\n",
            "03e0d1|\u001b[1;32mOK\u001b[0m  |    10MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/b1403d31b7f22c174998ad073b551bf4.jpg\n",
            "4216bf|\u001b[1;32mOK\u001b[0m  |   9.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/91f09f37e8669677c575317601afb4bf.png\n",
            "0bc93e|\u001b[1;32mOK\u001b[0m  |   8.6MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/733924f44ac1d6c40c02b1e28d39a354.png\n",
            "e4d5c2|\u001b[1;32mOK\u001b[0m  |    11MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/cde252878ce5429ed9f273a079d982be.jpg\n",
            "07480e|\u001b[1;32mOK\u001b[0m  |   8.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/eb810f512575286cc93ac3842d21f7e6.jpeg\n",
            "a50be7|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/aaeaa6f19b5761f694528c8b48d5e382.jpg\n",
            "f0c987|\u001b[1;32mOK\u001b[0m  |   704KiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_899670e100532d5305fca7a6cfaa089a.jpg\n",
            "4eeadc|\u001b[1;32mOK\u001b[0m  |   3.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/d102d863388b25b0f28686e143f68b50.jpeg\n",
            "f44fed|\u001b[1;32mOK\u001b[0m  |   6.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_26f15ab979b961c5c2e57e06176a740a.jpg\n",
            "2967cc|\u001b[1;32mOK\u001b[0m  |   7.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/8eef074a95de16bc79cc585eeb1a2d24.jpg\n",
            "47aba6|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/f53194b420acb2921100b5d770c970a8.jpeg\n",
            "bd4697|\u001b[1;32mOK\u001b[0m  |   1.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/788a021ca4b47ea905b61f5705809698.jpg\n",
            "72fc80|\u001b[1;32mOK\u001b[0m  |   3.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/755ae14c7dc1fe4700b9110b373449a5.jpg\n",
            "8bef9e|\u001b[1;32mOK\u001b[0m  |   4.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/f18888e9566c75cd68636c0529625565.jpg\n",
            "ca53cb|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/4249903d9ebb57970bca317c62cafcc8.jpg\n",
            "e821c7|\u001b[1;32mOK\u001b[0m  |   4.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/87b674ce25ae66ab1df8ee3a0f02b6e5.jpg\n",
            "46cf64|\u001b[1;32mOK\u001b[0m  |   8.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/33b935e438fc56346e1fc6d09df47300.jpeg\n",
            "e6418c|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/b289c3bdf93563120c544c30862a94c8.png\n",
            "fd1cb0|\u001b[1;32mOK\u001b[0m  |    18MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/8e3760932f0f2d1672682d9aa95321f3.jpg\n",
            "03878f|\u001b[1;32mOK\u001b[0m  |   5.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/2fba2d201618a3a0b6390e0a05137334.jpeg\n",
            "2a715b|\u001b[1;32mOK\u001b[0m  |   5.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/ba93fdec52f794580b214e1c1ac7db31.jpg\n",
            "abed5a|\u001b[1;32mOK\u001b[0m  |    11MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/2dd0d773f5df65fe7b5fc1258736bed6.png\n",
            "28d55a|\u001b[1;32mOK\u001b[0m  |    11MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/47c97456e16f28ec60854e1a07ebe233.jpeg\n",
            "7f8237|\u001b[1;32mOK\u001b[0m  |    10MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/f024d209c9c0cbe34c32ebe956e0b918.jpeg\n",
            "6d0aac|\u001b[1;32mOK\u001b[0m  |   5.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/dd92fda43178f2f8b7e676b94a2c8b7c.jpeg\n",
            "f063e5|\u001b[1;32mOK\u001b[0m  |   4.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/361e4d47e8b78db4a35f50114682abd1.jpg\n",
            "51ff5a|\u001b[1;32mOK\u001b[0m  |    26MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/3900c30651a279c10d7a0ee7a4ae84e9.png\n",
            "eddbc5|\u001b[1;32mOK\u001b[0m  |    17MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/7c913988cd42ed526dd6db180a6a3549.jpeg\n",
            "4808d3|\u001b[1;32mOK\u001b[0m  |   1.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_21f44d5d4616d0a391f512ffed016008.jpg\n",
            "3713a3|\u001b[1;32mOK\u001b[0m  |    18MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/f29a257cc3604060525175bf8a2fb953.jpeg\n",
            "029c04|\u001b[1;32mOK\u001b[0m  |    28MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6807c4510db9444e046018139ea022c2.jpg\n",
            "182ef1|\u001b[1;32mOK\u001b[0m  |    23MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/213fcfec5553285813a43f64bbe206a6.png\n",
            "5f4e1a|\u001b[1;32mOK\u001b[0m  |   6.3MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/14ba4c4340a219840c5894cc3bf08a11.jpeg\n",
            "2e94e4|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5ac64457507e35acc7db1837e0a6e0a3.jpg\n",
            "d99a87|\u001b[1;32mOK\u001b[0m  |   2.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/0656902606f5fc643541772d8b0aed46.jpg\n",
            "d53548|\u001b[1;32mOK\u001b[0m  |   5.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6d0fb01129954066a196622a366b1983.jpg\n",
            "058c46|\u001b[1;32mOK\u001b[0m  |    18MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_cdf31ce1c98b61a50ac5d8561596c5a8.jpg\n",
            "510319|\u001b[1;32mOK\u001b[0m  |   1.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/214010be85abc9d83b0fdc2104ccff97.jpeg\n",
            "3c5c80|\u001b[1;32mOK\u001b[0m  |   3.2MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/d076244807230f8a9daa2c13b21b2308.jpg\n",
            "6d9e97|\u001b[1;32mOK\u001b[0m  |   5.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6521a8848f6b8cdb9185bcae3fc96eab.jpeg\n",
            "56dc23|\u001b[1;32mOK\u001b[0m  |   8.7MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/92651c7244c97aab38bf05e3cd7a7dee.jpg\n",
            "0a8a8f|\u001b[1;32mOK\u001b[0m  |    12MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/0ed1f4ceeff120c85cc8db12ce45f77a.jpg\n",
            "3085b5|\u001b[1;32mOK\u001b[0m  |   1.7MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/ecff7647e549391904b2e6a42e6a736a.jpeg\n",
            "54b9fa|\u001b[1;32mOK\u001b[0m  |   3.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5c00128abd1651041222eaacf7d5de3e.jpeg\n",
            "9f2e1d|\u001b[1;32mOK\u001b[0m  |    39MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/384deff3ebc6f4f9db7a523974f3a922.png\n",
            "4956cd|\u001b[1;32mOK\u001b[0m  |   1.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/eaa9a0b6f00c4d8b4c40216cda49dc4b.jpeg\n",
            "583e18|\u001b[1;32mOK\u001b[0m  |   8.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_c7d8d75a3b68d02db81458b07ec03398.jpg\n",
            "5c14f1|\u001b[1;32mOK\u001b[0m  |   3.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/1dc753fc62b195a2618721c802b9d343.jpeg\n",
            "bd3a82|\u001b[1;32mOK\u001b[0m  |   5.1MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/fa2d29bfb1e0c14382cc13c45ec05b60.jpg\n",
            "c52e31|\u001b[1;32mOK\u001b[0m  |   3.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/a546e472d6a315e0560df56ad33c6e92.jpeg\n",
            "bafde6|\u001b[1;32mOK\u001b[0m  |   2.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/44dd3daf06caa148a6bc9d32a2aa3424.jpeg\n",
            "320643|\u001b[1;32mOK\u001b[0m  |   7.6MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/9c74c3863e831ff892cd66a5e701f137.png\n",
            "156c24|\u001b[1;32mOK\u001b[0m  |    25MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5e53c748bcd7b13863a89ea44c7c4a69.png\n",
            "01ce9e|\u001b[1;32mOK\u001b[0m  |   5.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_60bb7fab9734ebcd76f83da71755c252.jpg\n",
            "ff4a4a|\u001b[1;32mOK\u001b[0m  |    18MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/b093216beedf4661d3273bd84e69efd1.jpeg\n",
            "2906fe|\u001b[1;32mOK\u001b[0m  |   3.5MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/f560028b18dde03ae55913384e5daf99.jpeg\n",
            "ac4fa6|\u001b[1;32mOK\u001b[0m  |   2.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/sample_f6e8fec7fb8dcc7fbade0a2cc7c074d2.jpg\n",
            "ef64f1|\u001b[1;32mOK\u001b[0m  |    22MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/7d5ef323e1ed1a2d47cba757c9373b07.jpg\n",
            "be62ad|\u001b[1;32mOK\u001b[0m  |   5.7MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5b92b5f0a56f432de36ec696ca6c812d.jpg\n",
            "8e6b95|\u001b[1;32mOK\u001b[0m  |    10MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/789402d716843ddc0b652bdc3d04ab09.jpeg\n",
            "cc5396|\u001b[1;32mOK\u001b[0m  |    23MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/6dc6f7ae80a9a0fa8437c0cf9f1b786e.png\n",
            "74e8e3|\u001b[1;32mOK\u001b[0m  |    20MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5ad95c662a2e038c89b32c3a514cacd0.jpeg\n",
            "6c2fac|\u001b[1;32mOK\u001b[0m  |    27MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/a669597e3925b007de08a68052173cf5.png\n",
            "eec5b9|\u001b[1;32mOK\u001b[0m  |   5.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/a07265c535276da66b6b6bac23078146.jpg\n",
            "72b90e|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/80d41f42c6f68b3b2a59d6680777cb67.png\n",
            "55d388|\u001b[1;32mOK\u001b[0m  |   9.3MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/b5f38941d6f2dbe508c176a1dea26518.jpeg\n",
            "369658|\u001b[1;32mOK\u001b[0m  |    18MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/3da454752a7a902543a55bf753412762.jpg\n",
            "caa8c5|\u001b[1;32mOK\u001b[0m  |   1.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/76a496435ef912e4cd70f429c8e21682.jpeg\n",
            "b4efc8|\u001b[1;32mOK\u001b[0m  |   7.9MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/c700c7f0855809d2193ea614dac986ef.png\n",
            "0cab93|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/5f45e8afd0c79bb76430a9307ea9bdc8.png\n",
            "e07f1d|\u001b[1;32mOK\u001b[0m  |   6.7MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/a83933df654d860a26699fbb53f9bcad.jpeg\n",
            "34a3e5|\u001b[1;32mOK\u001b[0m  |    24MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/c78c9b395a20a7b75c01623ed68d038c.png\n",
            "feff91|\u001b[1;32mOK\u001b[0m  |    23MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/4b64eacb2f86e8813f683bfd8d88f000.png\n",
            "e56a92|\u001b[1;32mOK\u001b[0m  |   5.0MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/ce921ddd2446c3f859c2d4dc8c07e4cc.jpeg\n",
            "9ef24b|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/51a044357ecf456ce627e619aceeec9f.jpg\n",
            "6ca61f|\u001b[1;32mOK\u001b[0m  |   2.4MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/00cdc02b3dcac7e809164b05bafd7dcc.jpeg\n",
            "d54327|\u001b[1;32mOK\u001b[0m  |   1.8MiB/s|/content/drive/MyDrive/lora_training/datasets/Sofia/dd5ade5e8a62753f19f5a4b7b3677453.png\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "‚úÖ Se han descargado 112 im√°genes.\n"
          ]
        }
      ],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "import json\n",
        "import time\n",
        "from urllib.request import urlopen, Request\n",
        "\n",
        "#@markdown ### 2Ô∏è‚É£ Obtener im√°genes\n",
        "\n",
        "#@markdown Obtendremos im√°genes de la galer√≠a de anime llamada [Gelbooru](https://gelbooru.com/). Las im√°genes se organizan por miles de tags que describen todo acerca de una imagen. <p>\n",
        "#@markdown * Si quieres encontrar y usar tus propias im√°genes, ponlas dentro de la carpeta `lora_training/datasets/nombre_proyecto` en tu Google Drive.\n",
        "#@markdown * Si quieres descargar capturas de episodios de anime, existe [este otro colab de otra persona](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7) aunque aquel es m√°s complicado.\n",
        "\n",
        "#@markdown Hasta 1000 im√°genes se descargar√°n en un minuto, no debes abusar de ello. <p>\n",
        "#@markdown Tus tags deben ser relevantes para lo que desees entrenar, y excluir elementos no deseados (el contenido expl√≠cito puede hacer m√°s dif√≠cil el entrenamiento).\n",
        "#@markdown Las palabras van separadas por guionbajos, las tags van separadas por espacios, y usa - para excluir esa tag. Tambi√©n puedes incluir una puntuaci√≥n m√≠nima: `score:>10`\n",
        "tags = \"mavis_dracula\" #@param {type:\"string\"}\n",
        "#markdown Si una imagen supera esta resoluci√≥n, se descargar√° una versi√≥n m√°s peque√±a.\n",
        "max_resolution = 3072 #param {type:\"slider\", min:1024, max:8196, step:1024}\n",
        "#markdown Posts with a parent post are often minor variations of the same image.\n",
        "include_posts_with_parent = True #param {type:\"boolean\"}\n",
        "\n",
        "tags = tags.replace(\" \", \"+\")\\\n",
        "           .replace(\"(\", \"%28\")\\\n",
        "           .replace(\")\", \"%29\")\\\n",
        "           .replace(\":\", \"%3a\")\\\n",
        "          \n",
        "url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
        "user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
        "limit = 100 # hardcoded by gelbooru\n",
        "total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "def ubuntu_deps(url):\n",
        "  print(\"üè≠ Instalando...\\n\")\n",
        "  if not COLAB:\n",
        "    !apt -y install aria2\n",
        "    return not get_ipython().__dict__['user_ns']['_exit_code']\n",
        "  !apt -y install libunwind8-dev -q\n",
        "  !wget -q --show-progress {url}\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  with zipfile.ZipFile(url[url.rfind(\"/\")+1:], 'r') as deps:\n",
        "    deps.extractall(deps_dir)\n",
        "  !dpkg -i {deps_dir}/*\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  os.remove(url[url.rfind(\"/\")+1:])\n",
        "  shutil.rmtree(deps_dir)\n",
        "  return True\n",
        "\n",
        "if \"step2_installed_flag\" not in globals():\n",
        "  if ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\"):\n",
        "    clear_output()\n",
        "    step2_installed_flag = True\n",
        "  else:\n",
        "    print(\"‚ùå Error en la instalaci√≥n, intentando continuar...\")\n",
        "\n",
        "def get_json(url):\n",
        "  with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
        "    return json.load(page)\n",
        "\n",
        "def filter_images(data):\n",
        "  return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
        "          for p in data[\"post\"]\n",
        "          if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
        "          and p[\"file_url\"].lower().endswith(supported_types)]\n",
        "\n",
        "def download_images():\n",
        "  data = get_json(url)\n",
        "  count = data[\"@attributes\"][\"count\"]\n",
        "\n",
        "  if count == 0:\n",
        "    print(\"üì∑ No se encontraron resultados.\")\n",
        "    return\n",
        "\n",
        "  print(f\"üéØ Se encontraron {count} resultados\")\n",
        "  test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "  display(Markdown(f\"[¬°Click aqu√≠ para verlos en tu navegador!]({test_url})\"))\n",
        "  \n",
        "  print(\"üì© Obteniendo lista de im√°genes...\")\n",
        "\n",
        "  image_urls = set()\n",
        "  image_urls = image_urls.union(filter_images(data))\n",
        "  for i in range(total_limit // limit):\n",
        "    count -= limit\n",
        "    if count <= 0:\n",
        "      break\n",
        "    time.sleep(0.1)\n",
        "    image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
        "\n",
        "  scrape_file = os.path.join(config_folder, f\"scrape_{project_subfolder}.txt\")\n",
        "  with open(scrape_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(image_urls))\n",
        "\n",
        "  print(f\"üåê Enlaces guardados a {scrape_file}\\n\\nüîÅ Descargando im√°genes ...\\n\")\n",
        "  old_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "\n",
        "  os.chdir(images_folder)\n",
        "  !aria2c --console-log-level=warn -c -x 16 -k 1M -s 16 -i {scrape_file}\n",
        "\n",
        "  new_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "  print(f\"\\n‚úÖ Se han descargado {new_img_count - old_img_count} im√°genes.\")\n",
        "\n",
        "download_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sl4FD7Mz-uea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9e621d-7e9b-44fb-8daf-3762d944714c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üö∂‚Äç‚ôÇÔ∏è Iniciando programa...\n",
            "\n",
            "env: PYTHONPATH=/content/kohya-trainer\n",
            "downloading wd14 tagger model from hf_hub. id: SmilingWolf/wd-v1-4-swinv2-tagger-v2\n",
            "Downloading (‚Ä¶)\"keras_metadata.pb\";: 100% 448k/448k [00:00<00:00, 9.83MB/s]\n",
            "Downloading (‚Ä¶)\"saved_model.pb\";: 100% 37.6M/37.6M [00:00<00:00, 98.9MB/s]\n",
            "Downloading (‚Ä¶)in/selected_tags.csv: 100% 254k/254k [00:00<00:00, 7.19MB/s]\n",
            "Downloading (‚Ä¶)ata-00000-of-00001\";: 100% 385M/385M [00:02<00:00, 154MB/s]\n",
            "Downloading (‚Ä¶)\"variables.index\";: 100% 24.2k/24.2k [00:00<00:00, 3.07MB/s]\n",
            "found 112 images.\n",
            "loading model and labels\n"
          ]
        }
      ],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### 4Ô∏è‚É£ Descripciones de im√°genes\n",
        "#@markdown Usaremos inteligencia artificial para describir tus im√°genes, espec√≠ficamente [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2) en el caso de anime (etiquetas/tags) y [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) en el caso de fotorealismo (subt√≠tulos/captions).\n",
        "#@markdown Estas descripciones que van junto a tus im√°genes mejoran notablemente la calidad de tu Lora a la hora de entrenar. <p>\n",
        "metodo = \"Anime\" #@param [\"Anime\", \"Fotorealismo\"]\n",
        "method = metodo\n",
        "#@markdown **Anime:** El umbral es el nivel de certeza al que debe llegar la IA para asignar cada tag. Menor umbral = M√°s tags. Recomiendo 0.35 a 0.5\n",
        "umbral = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "tag_threshold = umbral\n",
        "#@markdown **Fotorealismo:** El m√≠nmimo y m√°ximo largo de cada subt√≠tulo (medido en tokens/palabras).\n",
        "largo_minimo = 10 #@param {type:\"number\"}\n",
        "caption_min = largo_minimo\n",
        "largo_maximo = 75 #@param {type:\"number\"}\n",
        "caption_max = largo_maximo\n",
        "\n",
        "%env PYTHONPATH=/env/python\n",
        "os.chdir(root_dir)\n",
        "kohya = \"/content/kohya-trainer\"\n",
        "if not os.path.exists(kohya):\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts {kohya}\n",
        "  os.chdir(kohya)\n",
        "  !git reset --hard ea1cf4aceea189e9c118b9ff190ca6be2de1adfb\n",
        "  os.chdir(root_dir)\n",
        "\n",
        "if \"Anime\" in method:\n",
        "  if \"step4a_installed_flag\" not in globals():\n",
        "    print(\"üè≠ Instalando...\\n\")\n",
        "    !pip -q install tensorflow==2.12.0 huggingface-hub==0.12.0 accelerate==0.15.0 transformers==4.26.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6 torchvision albumentations\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      clear_output()\n",
        "      step4a_installed_flag = True\n",
        "    else:\n",
        "      print(\"‚ùå Error en la instalaci√≥n, intentando continuar...\")\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Iniciando programa...\\n\")\n",
        "\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/tag_images_by_wd14_tagger.py \\\n",
        "    {images_folder} \\\n",
        "    --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 \\\n",
        "    --model_dir={root_dir} \\\n",
        "    --thresh={tag_threshold} \\\n",
        "    --batch_size=8 \\\n",
        "    --caption_extension=.txt \\\n",
        "    --force_download\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    print(\"removing underscores...\")\n",
        "    from collections import Counter\n",
        "    top_tags = Counter()\n",
        "    for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        tags = [t.strip() for t in f.read().split(\",\")]\n",
        "        tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
        "      top_tags.update(tags)\n",
        "      with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "        f.write(\", \".join(tags))\n",
        "\n",
        "    %env PYTHONPATH=/env/python\n",
        "    clear_output()\n",
        "    print(f\"üìä Finalizado. Aqu√≠ est√°n las 50 tags m√°s comunes en tus im√°genes:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "\n",
        "\n",
        "else: # Photorealism\n",
        "  if \"step4b_installed_flag\" not in globals():\n",
        "    print(\"üè≠ Instalando...\\n\")\n",
        "    !pip -q install timm==0.6.12 fairscale==0.4.13 transformers==4.26.0 requests==2.28.2 accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      clear_output()\n",
        "      step4b_installed_flag = True\n",
        "    else:\n",
        "      print(\"‚ùå Error en la instalaci√≥n, intentando continuar...\")\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Iniciando programa...\\n\")\n",
        "\n",
        "  os.chdir(kohya)\n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/make_captions.py \\\n",
        "    {images_folder} \\\n",
        "    --beam_search \\\n",
        "    --max_data_loader_n_workers=2 \\\n",
        "    --batch_size=8 \\\n",
        "    --min_length={caption_min} \\\n",
        "    --max_length={caption_max} \\\n",
        "    --caption_extension=.txt\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    import random\n",
        "    captions = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    %env PYTHONPATH=/env/python\n",
        "    clear_output()\n",
        "    print(f\"üìä Finalizado. Aqu√≠ hay {len(sample)} ejemplos de subt√≠tulos en tus im√°genes:\")\n",
        "    print(\"\".join(sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBFik7accyDz"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### 5Ô∏è‚É£ Filtra tus tags\n",
        "#@markdown Puedes hacer modificaciones en las tags de tus im√°genes cuantas veces quieras. <p>\n",
        "\n",
        "#@markdown A√±adir una palabra de activaci√≥n a tu Lora, √∫til para mejorar el entrenamiento y usarlo en tus prompts. En el entrenamiento debes poner `keep_tokens` igual a 1.<p>\n",
        "#@markdown Si quitas tags comunes como el color de pelo/ojos √©stas ser√°n \"absorbidas\" por tu palabra de activaci√≥n.\n",
        "palabra_de_activacion = \"\" #@param {type:\"string\"}\n",
        "global_activation_tag = palabra_de_activacion\n",
        "quitar_tags = \"virtual youtuber\" #@param {type:\"string\"}\n",
        "remove_tags = quitar_tags\n",
        "#@markdown <p>&nbsp;<p> En esta zona avanzada puedes realizar reemplazos o combinaciones de tags para as√≠ mejorar su calidad. Puedes reemplazar 1 tag por varias, o varias por 1, o una por otra, etc. Tambi√©n puedes a√±adir palabras de activaci√≥n espec√≠ficas.\n",
        "buscar_tags = \"\" #@param {type:\"string\"}\n",
        "search_tags = buscar_tags\n",
        "reemplazar_con = \"\" #@param {type:\"string\"}\n",
        "replace_with = reemplazar_con\n",
        "modo_de_busqueda = \"OR (puede tener cualquiera)\" #@param [\"OR (puede tener cualquiera)\", \"AND (debe tener todo)\"]\n",
        "search_mode = modo_de_busqueda\n",
        "tag_nueva_se_convierte_en_palabra_de_activacion = False #@param {type:\"boolean\"}\n",
        "new_becomes_activation_tag = tag_nueva_se_convierte_en_palabra_de_activacion\n",
        "#@markdown Estas pueden ser √∫tiles a veces. Ten cuidado, pueden quitar las palabras de activaci√≥n previas.\n",
        "ordenar_alfabeticamente = False #@param {type:\"boolean\"}\n",
        "sort_alphabetically = ordenar_alfabeticamente\n",
        "quitar_duplicados = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = quitar_duplicados\n",
        "\n",
        "def split_tags(tagstr):\n",
        "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "  if remove_duplicates:\n",
        "    tags = list(set(tags))\n",
        "  if sort_alphabetically:\n",
        "    tags.sort()\n",
        "\n",
        "  for rem in remove_tags_list:\n",
        "    if rem in tags:\n",
        "      remove_count += 1\n",
        "      tags.remove(rem)\n",
        "\n",
        "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
        "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
        "    replace_count += 1\n",
        "    for rem in search_tags_list:\n",
        "      if rem in tags:\n",
        "        tags.remove(rem)\n",
        "    for add in replace_with_list:\n",
        "      if add not in tags:\n",
        "        tags.append(add)\n",
        "    for new in replace_new_list:\n",
        "      if new_becomes_activation_tag:\n",
        "        if new in tags:\n",
        "          tags.remove(new)\n",
        "        tags.insert(0, new)\n",
        "      else:\n",
        "        if new not in tags:\n",
        "          tags.append(new)\n",
        "\n",
        "  for act in activation_tag_list:\n",
        "    if act in tags:\n",
        "      tags.remove(act)\n",
        "    tags.insert(0, act)\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "    f.write(\", \".join(tags))\n",
        "\n",
        "if remove_tags:\n",
        "  print(f\"\\nüöÆ Se han quitado {remove_count} tags.\")\n",
        "if search_tags:\n",
        "  print(f\"\\nüí´ Se han hecho {replace_count} reemplazos.\")\n",
        "print(\"\\n‚úÖ ¬°Listo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HuJB7BGAyZCw"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 6Ô∏è‚É£  Listo\n",
        "#@markdown Ahora debes estar listo para [entrenar tu Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb).\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"ü¶Ä [Click aqu√≠ para abrir el colab de entrenamiento](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDB9GXRONfiU"
      },
      "source": [
        "## *Ô∏è‚É£ Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xEsqOglcc6hA"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üìà Analizar tags\n",
        "#@markdown Volver a ver las tags m√°s comunes en tus im√°genes.\n",
        "ver_top = 50 #@param {type:\"number\"}\n",
        "show_top_tags = ver_top\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"üìä Tus {show_top_tags} tags m√°s comunes:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hcAHDi3zPjtg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Extraer datos\n",
        "#@markdown Es lento subir muchos archivos peque√±os, si quieres puedes subir un zip y extraerlo aqu√≠.\n",
        "zip = \"/content/drive/MyDrive/lora_training/datasets/warrior.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/lora_training/datasets/\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AdGcZRyPmtm"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Contar archivos\n",
        "#@markdown Google Drive hace imposible contar los archivos en una carpeta, por lo que aqu√≠ puedes ver la cantidad de archivos en carpetas y subcarpetas.\n",
        "carpeta = \"/content/drive/MyDrive/lora_training/datasets\" #@param {type:\"string\"}\n",
        "folder = carpeta\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l0tzRu6xBqj9"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üöÆ Limpiar carpeta\n",
        "#@markdown Cuidado, borra todos los archivos que no sean im√°genes de la carpeta del proyecto.\n",
        "\n",
        "!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}